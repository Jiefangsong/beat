#!/usr/bin/env python

import sys, re, os, logging, copy
import shutil

from optparse import OptionParser

from beat import heart, config, utility, models, inputf, plotting
from beat.metropolis import get_trace_stats

from pyrocko import model, util

from pyrocko.guts import load, dump


logger = logging.getLogger('beat')

def d2u(d):
    return dict((k.replace('-','_'), v) for (k, v) in d.iteritems())

subcommand_descriptions = {
        'init':           'create a new EQ model project',
        'import':         'import data or results, from external format or '
                          'modeling results, respectively',
        'sample':         'sample the solution space of the problem',
        'build_gfs':      'build GF stores',
        'clone':          'clone EQ model project into new directory',
        'plot':           'plot specified setups or results'
    }

subcommand_usages = {
        'init':          'init <event_name> <event_date "YYYY-MM-DD"> '
                         '[options]',
        'import':        'import <event_name> [options]',
        'sample':        'sample <event_name> [options]',
        'build_gfs':     'build_gfs <event_name> [options]',
        'clone':         'clone <event_name> <cloned_event_name> [options]',
        'plot':          'plot <event_name> <plot_type> [options]',
    }

subcommands = subcommand_descriptions.keys()

program_name = 'beat'

usage = program_name + ''' <subcommand> <arguments> ... [options]
BEAT: Bayesian earthquake analysis tool
 Version 0.1alpha
author: Hannes Vasyuara-Bathke
email: hannes.vasyura-bathke@kaust.edu.sa

Subcommands:

    init            %(init)s
    clone           %(clone)s
    import          %(import)s
    build_gfs       %(build_gfs)s
    sample          %(sample)s
    plot            %(plot)s

To get further help and a list of available options for any subcommand run:

    beat <subcommand> --help

''' % d2u(subcommand_descriptions)


def add_common_options(parser):
    parser.add_option('--loglevel',
        action = 'store',
        dest = 'loglevel',
        type = 'choice',
        choices = ('critical', 'error', 'warning', 'info', 'debug'),
        default = 'info',
        help ='set logger level to '
              '"critical", "error", "warning", "info", or "debug". '
              'Default is "%default".')


def process_common_options(options, name):
    project_dir = os.path.join(options.main_path, name)
    util.ensuredir(project_dir)
    utility.setup_logging(project_dir, options.loglevel)


def die(message, err=''):
    sys.exit('%s: error: %s \n %s' % (program_name, message, err))


def cl_parse(command, args, setup=None, details=None):
    usage = subcommand_usages[command]
    descr = subcommand_descriptions[command]

    if isinstance(usage, basestring):
        usage = [usage]

    susage = '%s %s' % (program_name, usage[0])
    for s in usage[1:]:
        susage += '\n%s%s %s' % (' '*7, program_name, s)

    description = descr[0].upper() + descr[1:] + '.'

    if details:
        description = description + ' %s' % details

    parser = OptionParser(usage=susage, description=description)

    if setup:
        setup(parser)

    add_common_options(parser)
    (options, args) = parser.parse_args(args)
    process_common_options(options, name=args[0])
    return parser, options, args


def load_config(fn):
    try:
        config = load(filename=fn)
        assert isinstance(config, config.BEATconfig)

    except:
        die('cannot load BEAT config from file: %s' % fn)

    return config


def list_callback(option, opt, value, parser):
    out = [ival.lstrip() for ival in value.split(',')]
    setattr(parser.values, option.dest, out)


def command_init(args):

    def setup(parser):

        parser.add_option('--min_mag', dest='min_mag', type=float,
            default=6.,
            help='Minimum Mw for event, for catalog search.'
                 ' Default: "6.0"')

        parser.add_option('--main_path', dest='main_path', type='string',
            default='./',
            help='Main path (absolute) for creating directory structure.'
                 '  Default: current directory ./')

        parser.add_option('--datasets',
            default=['geodetic'], type='string',
            action='callback', callback=list_callback,
            help='Datasets to include in the setup; "geodetic, seismic".')

        parser.add_option('--mode', dest='mode',
            choices=['geometry', 'static', 'kinematic'],
            default='geometry',
            help='Inversion problem to solve; "geometry", "static",'
                 '"kinematic". Default: "geometry"')

        parser.add_option('--source_type', dest='source_type',
            choices=['DCSource', 'RectangularSource'],
            default='RectangularSource',
            help='Source type to solve for; "DCSource", "RectangularSource"'
                 '. Default: "RectangularSource"')

        parser.add_option('--n_sources', dest='n_sources', type='int',
            default=1,
            help='Integer Number of sources to invert for. Default: 1' )

        parser.add_option('--sampler', dest='sampler', type='string',
            default='SMC',
            help='Sampling algorithm to sample the solution space of the'
                 ' general problem; "SMC", "Metropolis". Default: "SMC"')

        parser.add_option('--hyper_sampler', dest='hyper_sampler',
            type='string', default='Metropolis',
            help='Sampling algorithm to sample the solution space of the'
                 ' hyperparameters only;'
                 '"SMC", "Metropolis". Default: "Metropolis"')

        parser.add_option('--use_custom', dest='use_custom',
            action='store_true',
            help='If set, a slot for a custom velocity model is being created'
                 ' in the configuration file.')

        parser.add_option('--individual_gfs', dest='individual_gfs',
            action='store_true',
            help="If set, Green's Function stores will be created individually"
                 " for each station!")

    parser, options, args = cl_parse('init', args, setup=setup)

    l = len(args)

    if l > 2 or l < 1:
        logger.error('Wrong number of input arguments!')
        parser.print_help()
        sys.exit(1)

    if l == 2:
        name, date = args
    elif l == 1:
        logger.info(
            'Doing no catalog search for event information!')
        name = args[0]
        date = None

    return config.init_config(name, date,
               min_magnitude=options.min_mag,
               main_path=options.main_path,
               datasets=options.datasets,
               mode=options.mode,
               source_type=options.source_type,
               n_sources=options.n_sources,
               sampler=options.sampler,
               hyper_sampler=options.hyper_sampler,
               use_custom=options.use_custom,
               individual_gfs=options.individual_gfs)


def command_import(args):

    def setup(parser):

        parser.add_option('--main_path', dest='main_path', type='string',
            default='./',
            help='Main path (absolute) leading to folders of events that'
                 ' have been created by "init".'
                 ' Default: current directory: ./')

        parser.add_option('--results', dest='results', action='store_true',
                help='Import results from previous modeling step.')

        parser.add_option('--datasets',
            default=['geodetic'], type='string',
            action='callback', callback=list_callback,
            help='Datasets to import; "geodetic, seismic".')

        parser.add_option('--geodetic_format', dest='geodetic_format',
            type='string', default='matlab',
            help='Data format to be imported; "matlab", ...,'
                 ' Default: "matlab"')

        parser.add_option('--seismic_format', dest='seismic_format',
            type='string', default='autokiwi',
            help='Data format to be imported; "autokiwi", ...,'
                 'Default: "autokiwi"')

        parser.add_option('--mode', dest='mode',
            choices=['geometry', 'static', 'kinematic'],
            default='geometry',
            help='Inversion problem to solve; "geometry", "static",'
                 '"kinematic". Default: "geometry"')

        parser.add_option('--force', dest='force', action='store_true',
                help='Overwrite existing files')

    parser, options, args = cl_parse('import', args, setup=setup)

    try:
        name = args.pop()
    except:
        parser.error('cannot get <event_name> argument')
        parser.print_help()

    main_path = os.getcwd()
    project_dir = os.path.join(main_path, name)

    c = config.load_config(project_dir, options.mode)

    pc = c.problem_config

    if not options.results:
        if 'seismic' in options.datasets:
            sc = c.seismic_config
            logger.info('Attempting to import seismic data from %s' % \
                sc.datadir)

            seismic_outpath = os.path.join(
                c.project_dir, config.seismic_data_name)
            if not os.path.exists(seismic_outpath) or options.force:

                if options.seismic_format == 'autokiwi':

                    stations = model.load_stations(
                        os.path.join(sc.datadir,'stations.txt'))

                    data_traces = inputf.load_data_traces(
                        datadir=sc.datadir,
                        stations=stations,
                        channels=sc.channels)

                    logger.info('Pickle seismic data to %s' % seismic_outpath)
                    utility.dump_objects(seismic_outpath,
                        outlist=[stations, data_traces])
                else:
                    raise Exception(
                        'Format: %s not implemented yet.' % \
                        options.seismic_format)
            else:
                logger.info('%s exists! Use --force to overwrite!' % \
                    seismic_outpath)

        if 'geodetic' in options.datasets:
            gc = c.geodetic_config
            logger.info('Attempting to import geodetic data from %s' % \
                gc.datadir)

            geodetic_outpath = os.path.join(
                c.project_dir, config.geodetic_data_name)
            if not os.path.exists(geodetic_outpath) or options.force:

                if options.geodetic_format == 'matlab':
                    gtargets = inputf.load_SAR_data(gc.datadir, gc.tracks)

                    logger.info('Pickle geodetic data to %s' % geodetic_outpath)
                    utility.dump_objects(geodetic_outpath, outlist=gtargets)
                else:
                    raise Exception(
                        'Format: %s not implemented yet.' % \
                        options.geodetic_format)
            else:
                logger.info('%s exists! Use --force to overwrite!' % \
                    geodetic_outpath)

    else:
        if options.mode == 'geometry':
            logger.warn('No previous modeling results to be imported!')

        elif options.mode == 'static':
            logger.info('Importing non-linear modeling results, i.e.'
                ' maximum likelihood result for source geometry.')
            problem = models.load_model(
                c.project_dir, 'geometry', hypers=False)
            stage = models.load_stage(
                problem, stage_number='final', load='full')

            point = plotting.get_result_point(stage, problem.config, 'max')
            n_sources = problem.config.problem_config.n_sources

            source_params = config.geo_vars_geometry
            for param in point.keys():
                if param not in source_params:
                    point.pop(param)

            point = utility.adjust_point_units(point)
            source_points = utility.split_point(point)
            reference_sources = [heart.RectangularSource(
                    **source_points[i]) for i in range(n_sources)]

            c.geodetic_config.gf_config.reference_sources=reference_sources
            config.dump_config(c)
            logger.info('Successfully updated config file!')

def command_clone(args):

    def setup(parser):

        parser.add_option('--main_path', dest='main_path', type='string',
            default='./',
            help='Main path (absolute) leading to folders of events that'
                 ' have been created by "init".'
                 ' Default: current directory: ./')

        parser.add_option('--datasets',
            default=['geodetic', 'seismic'], type='string',
            action='callback', callback=list_callback,
            help='Datasets to clone; "geodetic, seismic".')

        parser.add_option('--mode',
            default=config.modes_catalog.keys(), type='string',
            action='callback', callback=list_callback,
            help='Inversion problem configs to clone if available;'
                 ' "geometry", "static", "kinematic". Default: all')

        parser.add_option('--copy_data', dest='copy_data',
            action='store_true',
            help='If set, the imported data will be copied into the cloned'
                 ' directory.')

    parser, options, args = cl_parse('clone', args, setup=setup)

    if not len(args) == 2:
        parser.print_help()
        sys.exit(1)

    name, cloned_name = args

    main_path = os.getcwd()
    project_dir = os.path.join(main_path, name)
    cloned_dir = os.path.join(main_path, cloned_name)

    util.ensuredir(cloned_dir)

    for mode in options.mode:
        config_fn = os.path.join(project_dir, 'config_' + mode + '.yaml')
        if os.path.exists(config_fn):
            logger.info('Cloning %s problem config.' % mode)
            c = config.load_config(project_dir, mode)
            c.name = cloned_name
            c.project_dir = cloned_dir

            new_datasets = []
            for dataset in  options.datasets:
                if dataset not in c.problem_config.datasets:
                    logger.warn(
                        'Dataset %s to be cloned is not in config!' % dataset)
                else:
                    new_datasets.append(dataset)

                    data_path = os.path.join(
                        project_dir, dataset + '_data.pkl')

                    if os.path.exists(data_path) and options.copy_data:
                        logger.info('Cloning %s data.' % dataset)
                        cloned_data_path = os.path.join(
                            cloned_dir, dataset + '_data.pkl')
                        shutil.copyfile(data_path, cloned_data_path)

            old_priors = copy.deepcopy(c.problem_config.priors)

            c.problem_config.datasets = new_datasets
            new_priors = c.problem_config.select_variables()

            for prior in new_priors:
                if prior in old_priors.keys():
                    c.problem_config.priors[prior] = old_priors[prior]

            old_hypers = copy.deepcopy(c.problem_config.hyperparameters)

            c.update_hypers()
            for hyper in old_hypers.keys():
                c.problem_config.hyperparameters[hyper] = old_hypers[hyper]

            config.dump_config(c)

        else:
            raise Exception('Config file: %s does not exist!' % config_fn)

def command_sample(args):

    def setup(parser):
        parser.add_option('--mode', dest='mode',
            choices=['geometry', 'static', 'kinematic'],
            default='geometry',
            help='Inversion problem to solve; "geometry", "static",'
                 '"kinematic". Default: "geometry"')

        parser.add_option('--main_path', dest='main_path', type='string',
            default='./',
            help='Main path (absolute) leading to folders of events that'
                 ' have been created by "init".'
                 ' Default: current directory: ./')

        parser.add_option('--hypers', dest='hypers',
                action='store_true', help='Sample hyperparameters only.')

    parser, options, args = cl_parse('sample', args, setup=setup)

    try:
        name = args.pop()
    except:
        parser.error('cannot get <event_name> argument')
        parser.print_help()

    os.chdir(options.main_path)
    main_path = os.getcwd()
    project_dir = os.path.join(main_path, name)

    problem = models.load_model(
        project_dir, options.mode, options.hypers)

    step = problem.init_sampler(hypers=options.hypers)

    if options.hypers:
        models.estimate_hypers(step, problem)
    else:
        models.sample(step, problem)


def command_build_gfs(args):

    def setup(parser):

        parser.add_option('--main_path', dest='main_path', type='string',
            default='./',
            help='Main path (absolute) leading to folders of events that'
                 ' have been created by "init".'
                 ' Default: current directory: ./')

        parser.add_option('--mode', dest='mode',
            choices=['geometry', 'static', 'kinematic'],
            default='geometry',
            help='Inversion problem to calculate GFs for; "geometry",'
                 '"static", "kinematic". Default: "geometry"')

        parser.add_option('--datasets',
            default='geodetic', type='string',
            action='callback', callback=list_callback,
            help='Datasets to calculate the GFs for; "geodetic, seismic".'
                 ' Default: "geodetic"')

        parser.add_option('--force', dest='force', action='store_true',
                help='Overwrite existing files')

        parser.add_option('--execute', dest='execute', action='store_true',
                help='Start actual GF calculations. If not set only'
                     ' configuration files are being created')

    parser, options, args = cl_parse('build_gfs', args, setup=setup)

    try:
        name = args.pop()
    except:
        parser.error('cannot get <event_name> argument')
        parser.print_help()

    os.chdir(options.main_path)
    main_path = os.getcwd()
    project_dir = os.path.join(main_path, name)

    c = config.load_config(project_dir, options.mode)

    if options.mode == 'geometry':
        if 'geodetic' in options.datasets:
            gf = c.geodetic_config.gf_config

            for crust_ind in range(gf.n_variations + 1):
                heart.geo_construct_gf(
                    event=c.event,
                    store_superdir=gf.store_superdir,
                    source_depth_min=gf.source_depth_min,
                    source_depth_max=gf.source_depth_max,
                    source_depth_spacing=gf.source_depth_spacing,
                    source_distance_min=gf.source_distance_min,
                    source_distance_max=gf.source_distance_max,
                    source_distance_spacing=gf.source_distance_spacing,
                    sampling_interval=gf.sampling_interval,
                    earth_model=gf.earth_model,
                    crust_ind=crust_ind,
                    use_crust2=gf.use_crust2,
                    custom_velocity_model=gf.custom_velocity_model,
                    replace_water=gf.replace_water,
                    execute=options.execute,
                    force=options.force)

            if options.execute:
                logger.info('Geodetic GF calculations successful!')

        if 'seismic' in options.datasets:
            sc = c.seismic_config
            sf = sc.gf_config

            if sf.reference_location is None:
                logger.info("Creating Green's Function stores individually"
                    " for each station!")
                seismic_data_path = os.path.join(
                    c.project_dir, config.seismic_data_name)

                stations, _ = utility.load_objects(seismic_data_path)
                stations = utility.apply_station_blacklist(
                    stations, sc.blacklist)
            else:
                logger.info(
                    "Creating one global Green's Function store, which is "
                    "being used by all stations!")
                stations = [sf.reference_location]
                logger.info('Store name: %s' % sf.reference_location.station)

            for crust_ind in range(sf.n_variations + 1):
                for station in stations:
                    heart.seis_construct_gf(
                        station=station,
                        event=c.event,
                        store_superdir=sf.store_superdir,
                        code=sf.code,
                        source_depth_min=sf.source_depth_min,
                        source_depth_max=sf.source_depth_max,
                        source_depth_spacing=sf.source_depth_spacing,
                        sample_rate=sf.sample_rate,
                        source_distance_radius=sf.source_distance_radius,
                        source_distance_spacing=sf.source_distance_spacing,
                        depth_limit_variation=sf.depth_limit_variation,
                        earth_model=sf.earth_model,
                        crust_ind=crust_ind,
                        use_crust2=sf.use_crust2,
                        execute=options.execute,
                        rm_gfs=sf.rm_gfs,
                        nworkers=sf.nworkers,
                        custom_velocity_model=sf.custom_velocity_model,
                        force=options.force)

            if not options.execute:
                logger.info('Seismic GF store configs successfully created! '
                            'To start calculations set --execute!')

            if options.execute:
                logger.info('Seismic GF calculations successful!')

    elif options.mode == 'static':
        geo = 'geodetic'
        if geo in options.datasets:
            gf = c.geodetic_config.gf_config

            geodetic_data_path = os.path.join(
                c.project_dir, config.geodetic_data_name)

            targets = utility.load_objects(geodetic_data_path)
            for target in targets:
                if target.los_vector is None:
                    target.update_los_vector()

            outdir = os.path.join(
                c.project_dir, options.mode, config.linear_gf_dir_name)
            util.ensuredir(outdir)

            for source in gf.reference_sources:
                source.update(lat=c.event.lat, lon=c.event.lon)

            varnames = [varname for varname in c.problem_config.priors.keys()]

            logger.info('Discretizing reference sources ...')
            fault = heart.discretize_sources(
                varnames=varnames,
                sources=gf.reference_sources,
                extension_width=gf.extension_width,
                extension_length=gf.extension_length,
                patch_width=gf.patch_width,
                patch_length=gf.patch_length,
                datasets=[geo])

            faultpath = os.path.join(outdir, config.fault_geometry_name)
            if os.path.exists(faultpath) and not options.force:
                logger.info("Discretized fault geometry exists! Use --force to"
                            " overwrite!")
                sys.exit(1)
            else:
                logger.info(
                    'Storing discretized fault geometry to: %s' % faultpath)
                utility.dump_objects(dsourcepath, [fault])

                logger.info('Updating problem_config:')
                logger.info(
                    'Number of source-sub-patches: %i' % fault.nsubpatches)
                c.problem_config.n_sources = n_sources
                c.problem_config.init_vars(varnames)
                config.dump_config(c)

            if options.execute:
                logger.info("Calculating linear Green's Functions...")
                for crust_ind in range(gf.n_variations + 1):
                    outpath = os.path.join(outdir,
                        str(crust_ind) + '_' + \
                        config.geodetic_linear_gf_name)
                    logger.info('crust_ind %i' % crust_ind)
                    heart.geo_construct_gf_linear(
                        store_superdir=gf.store_superdir,
                        outpath=outpath,
                        crust_ind=crust_ind,
                        targets=targets,
                        fault=fault,
                        varnames=varnames,
                        force=options.force)

            else:
                logger.info('Did not run GF calculation. Use --execute!')


def command_plot(args):

    def setup(parser):

        parser.add_option('--main_path', dest='main_path', type='string',
            default='./',
            help='Main path (absolute) leading to folders of events that'
                 ' have been created by "init".'
                 ' Default: current directory: ./')

        parser.add_option('--mode', dest='mode',
            choices=['geometry', 'static', 'kinemtic'],
            default='geometry',
            help='Inversion problem to calculate GFs for; "geometry",'
                 '"static", "kinematic". Default: "geometry"')

        parser.add_option('--post_llk', dest='post_llk',
            choices=['max', 'min', 'mean', 'all'],
            default='max',
            help='Plot model with specified likelihood; "max", "min", "mean"'
                 ' or "all"; Default: "max"')

        parser.add_option('--stage_number', dest='stage_number',
            default=None,
            help='String of the stage number "n" of the stage to be plotted.'
                 ' Default: all stages up to last complete stage')

        parser.add_option('--format', dest='format',
            choices=['display', 'pdf', 'png'],
            default='pdf',
            help='Output format of the plot; "display", "pdf" or "png"'
                 'Default: "pdf"')

        parser.add_option('--dpi', dest='dpi', type='int',
            default=300,
            help='Output resolution of the plots in dpi (dots per inch);'
                 ' Default: "300"')

        parser.add_option('--force', dest='force', action='store_true',
                help='Overwrite existing files')

        parser.add_option('--reference', dest='reference', action='store_true',
                help='Plot reference (test_point) into stage posteriors.')

        parser.add_option('--hypers', dest='hypers',
            action='store_true', help='Plot hyperparameter results only.')

    plots_avail = plotting.available_plots()

    details = '''Available <plot types> are: %s or "all". Multiple plots can be
selected giving a comma seperated list.''' % (
        ', '.join('"%s"' % plot for plot in plots_avail))

    parser, options, args = cl_parse('plot', args, setup, details)

    if len(args) != 2:
        parser.print_help()
        sys.exit(1)

    if args[1] == 'all':
        plotnames = plots_avail
    else:
        plotnames = args[1].split(',')

    for plot in plotnames:
        if plot not in plots_avail:
            raise Exception('Plot type %s not available! Available plots are:'
            ' %s' % (plot, plots_avail))

    os.chdir(options.main_path)
    main_path = os.getcwd()
    project_dir = os.path.join(main_path, args[0])

    logger.info('Loading problem ...')
    problem = models.load_model(project_dir, options.mode, options.hypers)

    po = plotting.PlotOptions(
        post_llk=options.post_llk,
        load_stage=options.stage_number,
        outformat=options.format,
        force=options.force,
        dpi=options.dpi)

    if options.reference:
        po.reference = problem.model.test_point
    else:
        po.reference = None

    figure_path = os.path.join(problem.outfolder, po.figure_dir)
    util.ensuredir(figure_path)

    for plot in plotnames:
        plotting.plots_catalog[plot](problem, po)


if __name__ == '__main__':

    usage_sub = 'BEAT %s [options]'
    if len(sys.argv) < 2:
        sys.exit('Usage: %s' % usage)

    args = list(sys.argv)
    args.pop(0)
    command = args.pop(0)

    if command in subcommands:
        globals()['command_'+ command](args)

    elif command in ('--help', '-h', 'help'):
        if command == 'help' and args:
            acommand = args[0]
            if acommand in subcommands:
                globals()['command_'+ acommand]([ '--help' ] )

        sys.exit('Usage: %s' % usage)

    else:
        sys.exit('BEAT: error: no such subcommand: %s' % command)

